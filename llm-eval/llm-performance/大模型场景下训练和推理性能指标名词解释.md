

| **指标**         | **含义**    |
| --------------------------- | ----------------- |
| token                       | token是文本的最小单位。在英文中，token 往往代表一个单词或一个标点符号；在中文中，token 往往代表一个字或词。                                                                                  |
| samples per second          | 每秒样本数，是指模型在训练或推理过程中每秒处理的样本数量，即训练时实际吞吐量。计算公式为：***samples/s = BS * N / step time***其中，BS为batch size，N为GPU/NPU的数量，step time是在分布式集群中执行完一个BS的时间（秒）。 |
| tokens per second           | NLP中常用的吞吐量指标，表示在单位时间内模型能够处理的token数量。用于评估模型的推理或训练性能。计算公式为：***tokens/s = token len / cost time***其中，token len为处理的文本中token的数量，cost time 为处理时间。     |
| TFLOPs                      | FLOPs是Floating-point Operations Per Second的缩写，代表每秒所执行的浮点运算次数。往往用TFLOPs衡量计算能力，即每秒执行万亿次浮点运算。                                                      |
| TP                          | 大模型训练时的并行策略，张量并行。可以将大模型的张量拆分为多个小块，分散到多个设备上，从而加快训练和推理的速度。详细可参考：[https://zhuanlan.zhihu.com/p/581677880]()                                        |
| PP                          | 大模型训练时的并行策略，流水线并行。可以将模型的层或模块划分为多个阶段，并在不同的设备上并行执行这些阶段，从而提高计算效率和吞吐量。详细可参考：[https://zhuanlan.zhihu.com/p/581677880]()                              |
| prompt                      | Prompt是一种由模型使用方提供的文本片段，用于在推理时引导大模型生成特定的输出。                                                                                                      |
| cost time (或Inference time) | 推理时间，指完成一次推理过程所需的总时间。包括加载模型、预处理输入、模型推理计算和后处理等步骤。耗时越短，意味着模型推理速度越快。 |





- https://bbs.huaweicloud.com/blogs/416186


